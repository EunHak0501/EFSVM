{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T16:03:25.609928Z",
     "start_time": "2024-08-09T16:03:25.574148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from cvxopt import solvers as cvxopt_solvers\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Team5_EFSVM:\n",
    "    def __init__(self, C, beta, k, m, gamma = 0, type_ = 'default', method='default'):\n",
    "        self.gamma = gamma\n",
    "        self.type_ = type_\n",
    "        self.method = method\n",
    "        self.C = C\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        self.m = m\n",
    "        self.kernel = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.alphas = None\n",
    "        self.S = None\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.support = None\n",
    "        self.entr = None\n",
    "        self.membership = None\n",
    "        self.si_array = None\n",
    "\n",
    "    # 커널 함수, kernel trick의 적용을 위함\n",
    "    def Kernel_(self, x, y, params = 0, type_ = 'default') :\n",
    "        Kernel = None\n",
    "        if type_ == 'rbf' :\n",
    "            Kernel = np.exp(- (np.sum(x **2, axis = 1).reshape(-1,1) + np.sum(y **2, axis = 1).reshape(1,-1) - 2 * x @ y.T)* params)\n",
    "        elif type_ == 'default' :\n",
    "            Kernel = np.dot(x, y.T)\n",
    "\n",
    "        self.kernel = Kernel\n",
    "        return Kernel\n",
    "\n",
    "\n",
    "    # 유클리드 거리 계산\n",
    "    def get_euclidean_distance(self, X):\n",
    "        return distance.cdist(X, X, metric = 'euclidean')\n",
    "\n",
    "\n",
    "    def cal_entropy(self, X, y, k):\n",
    "        entropy_list = []\n",
    "        eucli_distance = self.get_euclidean_distance(X)\n",
    "        # k값에 따라 negative class에 대해 euclidean distance를 기준으로 가까운 값의 인덱스를 저장\n",
    "        knn_neg = [np.argsort(eucli_distance[idx])[1:k+1] for idx, val in enumerate(y) if val < 0]\n",
    "        # 자기 자신은 제외 >> index 1부터 k+1까지\n",
    "        for indexs in knn_neg:\n",
    "            p_cnt = len([y[idx] for idx in indexs if y[idx] > 0])\n",
    "            p_pos = p_cnt / k # probability of positive\n",
    "            p_neg = 1 - p_pos # probability of negative\n",
    "            H_i = entropy([p_pos, p_neg]) # get entropy\n",
    "            entropy_list.append(H_i)\n",
    "\n",
    "        return entropy_list\n",
    "\n",
    "    def cal_entropy_index(self, m, l, thrUp, thrLow, entropy_list):\n",
    "        entropy_index = []\n",
    "        for i, H in enumerate(entropy_list):\n",
    "            if l==m:  # l이 m과 같은 경우(마지막 구간) H가 thrUp과 같을 수 있게 만들어줌\n",
    "                if thrLow <= H <= thrUp:\n",
    "                    entropy_index.append(i)\n",
    "            else:\n",
    "                if thrLow <= H < thrUp:\n",
    "                    entropy_index.append(i)\n",
    "        return entropy_index\n",
    "    \n",
    "    def divide_min_variance(self, list, m, method=1):\n",
    "        list = np.array(list)\n",
    "        n = len(list)\n",
    "        if method == 1:\n",
    "            # DP 테이블과 Breakpoints 테이블 초기화\n",
    "            dp = np.full((n + 1, m + 1), np.inf)  # 초기값을 무한대로 설정\n",
    "            breakpoints = np.zeros((n + 1, m + 1), dtype=int)\n",
    "    \n",
    "            # dp[i][1] 초기화: 첫 번째 구간의 분산 계산\n",
    "            for i in range(1, n + 1):\n",
    "                dp[i][1] = np.var(list[:i]) * i\n",
    "    \n",
    "                # DP 테이블 채우기\n",
    "            for j in range(2, m + 1):\n",
    "                for i in range(j, n + 1):\n",
    "                    min_variance = float('inf')\n",
    "                    best_k = -1\n",
    "                    for k in range(j - 1, i):\n",
    "                        current_variance = dp[k][j - 1] + np.var(list[k:i]) * (i - k)\n",
    "                        if current_variance < min_variance:\n",
    "                            min_variance = current_variance\n",
    "                            best_k = k\n",
    "                    dp[i][j] = min_variance\n",
    "                    breakpoints[i][j] = best_k\n",
    "    \n",
    "                segments = []\n",
    "            current = n\n",
    "            for j in range(m, 0, -1):\n",
    "                segments.append((breakpoints[current][j], current))\n",
    "                current = breakpoints[current][j]\n",
    "        \n",
    "            segments = sorted(segments)\n",
    "    \n",
    "            bins = []\n",
    "            for i, (start, end) in enumerate(segments):\n",
    "                thrLow = list[start] if i == 0 else list[start - 1]\n",
    "                thrUp = list[end - 1]\n",
    "                bins.append((thrLow, thrUp))\n",
    "        \n",
    "        elif method == 2:\n",
    "            print('Not implemented')\n",
    "            \n",
    "        return bins\n",
    "\n",
    "    #3 Entropy-based Fuzzy Membership 계산\n",
    "    def cal_fuzzy_membership(self, entropy_list, m, beta):\n",
    "        # len(entropy_list) == negative의 갯수\n",
    "        fuzzy_membership = {}\n",
    "        H_min = min(entropy_list)\n",
    "        H_max = max(entropy_list)\n",
    "        \n",
    "        if self.method == 'default': # 구간의 길이를 동일하게\n",
    "            for l in range(1, m + 1):\n",
    "                thrUp = H_min + (H_max - H_min) * (l / m)\n",
    "                thrLow = H_min + (H_max - H_min) * (l - 1) / m\n",
    "    \n",
    "                entropy_index = self.cal_entropy_index(m, l, thrUp, thrLow, entropy_list)\n",
    "                \n",
    "                if len(entropy_index) == 0: # Low, Up 조건에 맞는 엔트로피가 없으면 FM 계산 x\n",
    "                    continue\n",
    "    \n",
    "                fm = 1.0 - beta * l # cal fm\n",
    "                fuzzy_membership[fm] = entropy_index # entropy index를 해당하는 fm을 key로 한 value에 넣기\n",
    "                \n",
    "        elif self.method == 'same_frequent': # 각 구간에 동일한 갯수가 포함되게\n",
    "            sorted_entropy = np.sort(entropy_list)\n",
    "            bins = np.array_split(sorted_entropy, m)\n",
    "\n",
    "            for l in range(1, m + 1):\n",
    "                thrUp = bins[l-1][-1]\n",
    "                thrLow = bins[l-1][0]\n",
    "                \n",
    "                entropy_index = self.cal_entropy_index(m, l, thrUp, thrLow, entropy_list)\n",
    "                \n",
    "                if len(entropy_index) == 0: # Low, Up 조건에 맞는 엔트로피가 없으면 FM 계산 x\n",
    "                    continue\n",
    "\n",
    "                fm = 1.0 - beta * l # cal fm\n",
    "                fuzzy_membership[fm] = entropy_index # entropy index를 해당하는 fm을 key로 한 value에 넣기\n",
    "        \n",
    "        elif self.method == 'min_variance': # 각 구간의 분산이 최소가 되도록 (비슷한 엔트로피끼리 모이도록)\n",
    "            sorted_entropy = np.sort(entropy_list)\n",
    "            n = len(entropy_list)\n",
    "            bins = self.divide_min_variance(sorted_entropy, m)\n",
    "\n",
    "            for l in range(1, m + 1):\n",
    "                thrUp = bins[l-1][-1]\n",
    "                thrLow = bins[l-1][0]\n",
    "        \n",
    "                entropy_index = self.cal_entropy_index(m, l, thrUp, thrLow, entropy_list)\n",
    "        \n",
    "                if len(entropy_index) == 0: # Low, Up 조건에 맞는 엔트로피가 없으면 FM 계산 x\n",
    "                    continue\n",
    "        \n",
    "                fm = 1.0 - beta * l # cal fm\n",
    "                fuzzy_membership[fm] = entropy_index # entropy index를 해당하는 fm을 key로 한 value에 넣기\n",
    "            \n",
    "        return fuzzy_membership\n",
    "\n",
    "    # 4. Positive와 Negative class 모두에 대해 si 부여\n",
    "    def cal_si(self, X, fm, y):\n",
    "        si = []\n",
    "        neg_class = [idx for idx, val in enumerate(y) if val < 0] # negative class 찾기\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            if i in neg_class: # negative class에 대해 si 부여\n",
    "                for j in fm:\n",
    "                    if neg_class.index(i) in fm[j]: # y가 negative class이면서, fm에 포함되어 있는지 확인\n",
    "                        si.append(j)\n",
    "                        break\n",
    "            else: # positive class에 대해 si 부여\n",
    "                si.append(1.0)\n",
    "\n",
    "        return si\n",
    "\n",
    "    # convex optimization에 필요한 parameter들을 반환\n",
    "    def getValue(self, X, y):\n",
    "        Kernel = self.Kernel_(X, X, self.gamma, self.type_)\n",
    "\n",
    "        entr = self.cal_entropy(X, y, self.k)\n",
    "        self.entr = entr\n",
    "\n",
    "        membership = self.cal_fuzzy_membership(entr, self.m, self.beta)\n",
    "        self.membership = membership\n",
    "\n",
    "        si_array = np.array(self.cal_si(X, self.membership, y))\n",
    "        self.si_array = si_array\n",
    "\n",
    "        y = y.reshape(-1,1)\n",
    "        self.y = y\n",
    "        m,n = X.shape\n",
    "\n",
    "        H = self.kernel * (y @ y.T)\n",
    "        \n",
    "        P = cvxopt_matrix(H)\n",
    "        q = cvxopt_matrix(-np.ones((m, 1)))\n",
    "        G = cvxopt_matrix(np.vstack((-np.eye(m),np.eye(m))))\n",
    "        h = cvxopt_matrix(np.hstack((np.zeros(m), np.ones(m) * self.si_array * self.C))) # s_i를 추가적으로 이용\n",
    "        A = cvxopt_matrix(y.reshape(1, -1), tc='d')\n",
    "        b = cvxopt_matrix(np.zeros(1))\n",
    "\n",
    "        return P, q, G, h, A, b\n",
    "\n",
    "    # train data를 이용해서 convex optimization을 통해 모델을 학습\n",
    "    def solver(self, X, y):\n",
    "        cvxopt_solvers.options['show_progress'] = False # verbose = False\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        P, q, G, h, A, b = self.getValue(self.X, self.y)\n",
    "        sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        alphas = np.array(sol['x'])\n",
    "        self.alphas = alphas\n",
    "\n",
    "        if self.type_ == 'default':\n",
    "            w = ((self.y * self.alphas).T @ self.X).reshape(-1, 1)\n",
    "        else:\n",
    "            w = None # gaussian 일 때 w는 None.\n",
    "        S = ((self.alphas > 1e-4) & (self.alphas < self.C-1e-4)).flatten()\n",
    "        if self.type_ == 'rbf':\n",
    "            b = self.y[S] - np.sum(self.Kernel_(self.X, self.X[S], self.gamma, self.type_) * self.y * self.alphas, axis = 0).reshape(-1, 1) # gaussian\n",
    "        else:\n",
    "            b = self.y[S] - np.sum(self.Kernel_(self.X, self.X[S]) * self.y * self.alphas, axis = 0).reshape(-1, 1) # linear\n",
    "\n",
    "        self.w = w\n",
    "        self.S = S\n",
    "        self.b = b\n",
    "\n",
    "        # return alphas, S, w, b\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        test_X = np.array(test_X)\n",
    "        pred_sol = np.sign(np.sum(self.Kernel_(self.X, test_X, self.gamma, self.type_) * self.y * self.alphas, axis = 0).reshape(-1,1) + self.b[0])\n",
    "        return pred_sol\n",
    "\n"
   ],
   "id": "663a6b267a9271f2",
   "execution_count": 142,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:27:54.692929Z",
     "start_time": "2024-08-09T15:27:54.671932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Data load\n",
    "data_ = sns.load_dataset('titanic')\n",
    "\n",
    "# Data dropna\n",
    "data_['age'] = data_['age'].fillna(data_['age'].mean())\n",
    "data_ = data_.drop('deck',axis=1)\n",
    "data_ = data_.dropna(axis=0)\n",
    "\n",
    "# encoding\n",
    "replace_sex = {'male': 1, 'female': 0}\n",
    "data_['sex'] = data_['sex'].replace(replace_sex)\n",
    "data_['sex'].value_counts()\n",
    "\n",
    "replace_embark = {'Southampton': 3, 'Cherbourg': 2, 'Queenstown': 1}\n",
    "data_['embark_town'] = data_['embark_town'].replace(replace_embark)\n",
    "data_ = data_.drop(['embarked','class','who','adult_male','alive','alone'], axis=1)\n",
    "\n",
    "data_['survived'] = data_['survived'].replace({0:-1})\n",
    "data_['survived'].value_counts()"
   ],
   "id": "a3fda1c1a929cd5a",
   "execution_count": 122,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:27:55.019240Z",
     "start_time": "2024-08-09T15:27:55.008625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data_.iloc[:,1:]\n",
    "y = data_.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=30)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "y_train.value_counts()"
   ],
   "id": "b17842b7e9bce996",
   "execution_count": 123,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:29:40.471985Z",
     "start_time": "2024-08-09T15:29:40.175685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Team5_EFSVM(C=10, beta=0.01, k=10, m=10, gamma=0.1, type_='rbf', method='same_frequent')\n",
    "\n",
    "model.solver(X_train, y_train)"
   ],
   "id": "df05fefab11d44b3",
   "execution_count": 140,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:29:40.598029Z",
     "start_time": "2024-08-09T15:29:40.575119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "id": "a78904ffcab1d1e2",
   "execution_count": 141,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "F1 Score: 0.7231638418079096\n",
    "Accuracy: 0.7802690582959642"
   ],
   "id": "cb67ad694b32b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "F1 Score: 0.7231638418079096\n",
    "Accuracy: 0.7802690582959642"
   ],
   "id": "25d165b1efb9f988"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "b4b43ab5cc270b0a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
